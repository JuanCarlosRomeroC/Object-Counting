{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "from keras import Model\n",
    "from neural_networks.fcrn import FCRN_A\n",
    "from utils.data.data_generator import DataGenerator\n",
    "from utils.data.data_ops import move_val_split_to_train\n",
    "from utils.data.data_ops import create_val_split_from_train\n",
    "from utils.input_output.io import save_np_arrays\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'shanghai_tech/part_b'\n",
    "DATASET_PATH = f'../../datasets/{DATASET_NAME}'\n",
    "IMG_DIM = None\n",
    "D_MAP_MULT_FACT = None\n",
    "LOSS_FUNCTIONS = ['mse', 'mae', 'logcosh']\n",
    "EXP_DIR_NAMES = []\n",
    "\n",
    "if DATASET_NAME.lower() == 'vgg_cells':\n",
    "    # misc\n",
    "    IMG_DIM = (256, 256, 3)\n",
    "    D_MAP_MULT_FACT = 100.\n",
    "    \n",
    "    # plots\n",
    "    figsize=(25, 5)\n",
    "    fraction = 0.045\n",
    "    pad = 0.038\n",
    "    \n",
    "    # checkpoints\n",
    "    for loss_name in LOSS_FUNCTIONS:\n",
    "        for input_type in ['full_img', 'patch_32_128x128']:\n",
    "            for train_size in [32, 64]:\n",
    "                for rseed_idx in range(1, 6):\n",
    "                    exp_dir_name =  f'./vgg_cells/'\\\n",
    "                                    f'n_{train_size}_sigma_5_'\\\n",
    "                                    f'randseed_{train_size}{rseed_idx}_'\\\n",
    "                                    f'loss_{loss_name}_'\\\n",
    "                                    f'{input_type}'\n",
    "                    EXP_DIR_NAMES.append(exp_dir_name)\n",
    "    \n",
    "elif DATASET_NAME.lower() == 'carpk':\n",
    "    # misc\n",
    "    IMG_DIM = (720, 1280, 3)\n",
    "    D_MAP_MULT_FACT = 2000.\n",
    "    \n",
    "    # plots\n",
    "    figsize=(25, 7)\n",
    "    fraction = 0.027\n",
    "    pad = 0.015\n",
    "    \n",
    "    # checkpoints\n",
    "    EXP_DIR_NAMES = ['./carpk/sigma_10_loss_logcosh_patch_32_128x128_15_epochs']\n",
    "                    #['./carpk/sigma_10_loss_logcosh_patch_32_128x128_5_epochs']\n",
    "    \n",
    "elif DATASET_NAME.lower() == 'shanghai_tech/part_b':\n",
    "    # misc\n",
    "    IMG_DIM = (768, 1024, 3)\n",
    "    D_MAP_MULT_FACT = 2000.\n",
    "    \n",
    "    # plots\n",
    "    figsize=(25, 7)\n",
    "    fraction = 0.0355\n",
    "    pad = 0.015\n",
    "    \n",
    "    # checkpoints\n",
    "    EXP_DIR_NAMES = ['./shanghai_tech/part_b/sigma_10_loss_logcosh_full_img_epochs_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'dim': IMG_DIM,\n",
    "    'batch_size': 1,\n",
    "    'patches_per_image': 1,\n",
    "    'density_map_multiplication_factor': D_MAP_MULT_FACT,\n",
    "    'shuffle': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['./shanghai_tech/part_b/sigma_10_loss_logcosh_full_img_epochs_30']\n"
     ]
    }
   ],
   "source": [
    "print(len(EXP_DIR_NAMES))\n",
    "pprint(EXP_DIR_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for exp_dir_name in EXP_DIR_NAMES[:1]:\n",
    "    if 'vgg_cells' in DATASET_PATH:\n",
    "        # for vgg_cells dataset we divide the train set in different train/val split each time\n",
    "        train_path = f'{DATASET_PATH}/train'\n",
    "        val_path = f'{DATASET_PATH}/val'\n",
    "        \n",
    "        train_size = int(re.search(r'/n_\\d{2}_', exp_dir_name).group().split('_')[1])\n",
    "        val_size = 100 - train_size\n",
    "        rand_seed = int(re.search(r'randseed_\\d{3}_', exp_dir_name).group().split('_')[1])\n",
    "        \n",
    "        move_val_split_to_train(val_path, train_path)\n",
    "        create_val_split_from_train(train_path, val_path, val_size, rand_seed)\n",
    "        \n",
    "    # data splits\n",
    "    train_generator = DataGenerator(DATASET_PATH, 'train', **params)\n",
    "    val_generator = DataGenerator(DATASET_PATH, 'val', **params)\n",
    "    test_generator = DataGenerator(DATASET_PATH, 'test', **params)\n",
    "    \n",
    "    # clean old dir for qualitative results\n",
    "    results_path = f'{exp_dir_name}/results/qualitative'\n",
    "    shutil.rmtree(results_path, ignore_errors=True)\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "    # predict and save\n",
    "    checkpoint_filename = f'{exp_dir_name}/checkpoints/best_model.hdf5'\n",
    "    model = FCRN_A(pretrained_weights=checkpoint_filename)\n",
    "    \n",
    "    for data_generator, split_name in zip([train_generator, val_generator, test_generator],\n",
    "                                          ['train', 'val', 'test']):\n",
    "        # prepare dirs for qualitative results\n",
    "        results_path_npy = f'{results_path}/{split_name}/npy'\n",
    "        results_path_png = f'{results_path}/{split_name}/png'\n",
    "        results_path_png_diff = f'{results_path}/{split_name}/png_diff'\n",
    "        results_path_png_gt_asc = f'{results_path}/{split_name}/png_gt_asc'\n",
    "        os.makedirs(results_path_npy)\n",
    "        os.makedirs(results_path_png)\n",
    "        os.makedirs(results_path_png_diff)\n",
    "        os.makedirs(results_path_png_gt_asc)\n",
    "        \n",
    "        for idx in range(data_generator.__len__()):\n",
    "            # input image & gt density map, batch_size=1\n",
    "            input_img, gt_density_map = data_generator.__getitem__(idx)\n",
    "            gt_density_map /= D_MAP_MULT_FACT\n",
    "            \n",
    "            # predicted density map\n",
    "            pred_density_map = (model.predict(input_img) / D_MAP_MULT_FACT)[0]\n",
    "            \n",
    "            # gt & pred counts\n",
    "            gt_count = int(np.round(gt_density_map.sum()))\n",
    "            pred_count = pred_density_map.sum()\n",
    "            pred_gt_diff = pred_count - gt_count\n",
    "            \n",
    "            error_type = 'match'\n",
    "            if pred_count < gt_count:\n",
    "                error_type = 'underestimate'\n",
    "            elif pred_count > gt_count:\n",
    "                error_type = 'overestimate'\n",
    "            \n",
    "            img_name_png = data_generator.img_names[data_generator.indexes[idx]]\n",
    "            img_name = img_name_png.split('.')[0]\n",
    "            img_name_npy = f'{img_name}_gt_{gt_count}_pred_{pred_count:.2f}'\\\n",
    "                           f'_diff_gt_pred_{pred_gt_diff:.2f}'\n",
    "            img_name_diff = f'{error_type}_{np.abs(pred_gt_diff):7.2f}'\\\n",
    "                            f'_gt_{gt_count}_pred_{pred_count:.2f}'\\\n",
    "                            f'_{img_name}'.replace(' ', '0')\n",
    "            img_name_gt_asc = f'gt_{gt_count:3}_pred_{pred_count:6.2f}_diff_gt_pred_{pred_gt_diff:.2f}'\\\n",
    "                              f'_{img_name}'.replace(' ', '0')\n",
    "            \n",
    "            # .npy arrays\n",
    "            save_np_arrays([pred_density_map], [img_name_npy], results_path_npy)\n",
    "            \n",
    "            # plots\n",
    "            vmin = min(gt_density_map.min(), pred_density_map.min())\n",
    "            vmax = max(gt_density_map.max(), pred_density_map.max())\n",
    "            \n",
    "            fig = plt.figure(figsize=figsize)\n",
    "\n",
    "            plt.subplot(1, 4, 1)\n",
    "            plt.title('Input image')\n",
    "            plt.imshow(input_img[0])\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 4, 2)\n",
    "            plt.title(f'GT density map ({gt_count})')\n",
    "            plt.imshow(gt_density_map.squeeze(), cmap='jet', vmin=vmin, vmax=vmax)\n",
    "            plt.colorbar(fraction=fraction, pad=pad)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 4, 3)\n",
    "            plt.title(f'Predicted density map ({pred_count:.2f})')\n",
    "            plt.imshow(pred_density_map.squeeze(), cmap='jet', vmin=vmin, vmax=vmax)\n",
    "            plt.colorbar(fraction=fraction, pad=pad)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 4, 4)\n",
    "            plt.title(f'Prediction - GT ({(pred_density_map - gt_density_map).sum():.2f})')\n",
    "            plt.imshow((pred_density_map - gt_density_map).squeeze(), cmap='gray')\n",
    "            plt.colorbar(fraction=fraction, pad=pad)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.savefig(f'{results_path_png}/{img_name_npy}.png')\n",
    "            plt.savefig(f'{results_path_png_diff}/{img_name_diff}.png')\n",
    "            plt.savefig(f'{results_path_png_gt_asc}/{img_name_gt_asc}.png')\n",
    "            plt.clf()\n",
    "            plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
